<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="CoRe: Context-Regularized Text Embedding Learning for Text-to-Image Personalization">


  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Textual Inversion, DreamBooth, Attention, CoRe, Context-Regularized">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CoRe</title>

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CoRe: Context-Regularized Text Embedding Learning for Text-to-Image Personalization</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Feize Wu</a><sup>1*</sup>,</span>
                <span class="author-block">
                  Yun Pang</a><sup>1*</sup>,</span>
                <span class="author-block">
                  Junyi Zhang</a><sup>1*</sup>,</span>
                <span class="author-block">
                  Lianyu Pang</a><sup>1*</sup>,</span>
                  <span class="author-block">
                    Jian Yin</a><sup>1</sup>,</span>
                  <span class="author-block">
                    Baoquan Zhao</a><sup>1</sup>,</span>
                  <span class="author-block">
                    Qing Li</a><sup>2</sup>,</span>
                  <span class="author-block">
                    Xudong Mao</a><sup>1+</sup>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Sun Yat-sen University<br>
                      <sup>2</sup>The Hong Kong Polytechnic University
                      <!-- <br>Conferance name and year</span> -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>+</sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2408.15914" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://pangy9.github.io/CoRe-page/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(coming soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2408.15914" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png"/>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in text-to-image personalization have enabled high-quality and controllable image synthesis for user-provided concepts. However, existing methods still struggle to balance identity preservation with text alignment. Our approach is based on the fact that generating prompt-aligned images requires a precise semantic understanding of the prompt, which involves accurately processing the interactions between the new concept and its surrounding context tokens within the CLIP text encoder. To address this, we aim to embed the new concept properly into the input embedding space of the text encoder, allowing for seamless integration with existing tokens. We introduce Context Regularization (CoRe), which enhances the learning of the new concept's text embedding by regularizing its context tokens in the prompt. This is based on the insight that appropriate output vectors of the text encoder for the context tokens can only be achieved if the new concept's text embedding is correctly learned. CoRe can be applied to arbitrary prompts without requiring the generation of corresponding images, thus improving the generalization of the learned text embedding. Additionally, CoRe can serve as a test-time optimization technique to further enhance the generations for specific prompts. Comprehensive experiments demonstrate that our method outperforms several baseline methods in both identity preservation and text alignment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Motivation</h2>
      
      <div class="image-container" style="display: flex; justify-content: space-between;">
        <img src="static/images/cosine_similarity_comparison.png" alt="Cosine Similarity Comparison" class="blend-img-background" style="width: 48%;"/>
        <img src="static/images/attnmap.png" alt="Cross Attention Map Visualization" class="blend-img-background" style="width: 48%;"/>
      </div>
      <br>
      <div class="level-set has-text-justified">
        <p>
          For the four similar prompts (``{} in the desert''), we show the cosine similarity between the output embeddings of each token (left), and the cross-attention map visualization of each token (right). Replacing ``dog'' with ``puppy'' or ``cat'' results in similar output embeddings and attention maps for other tokens. In contrast, using the overfitted S<sup>*</sup> by Textual Inversion significantly alters the output embeddings and attention maps for other tokens. 
        </p>
        </p>
      </div>
    </div>
  </div>
</div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Overview</h2>
      
      <img src="static/images/framework.png" alt="Multi-Stage Finetuning of AttnDreamBooth" class="blend-img-background center-image"/>
      <br>
      <br>
      
      <div class="level-set has-text-justified">
        <p>
          Our method enhances the text embedding learning for S<sup>*</sup> by regularizing its context tokens. Specifically, we randomly select a regularization prompt (e.g., ``S<sup>*</sup> in the desert'') and a reference prompt (e.g., ``Dog in the desert'') from the prompt set. During training, the proposed context embedding regularization and context attention regularization are applied together with the diffusion loss, which encourages the representations of the context tokens surrounding S<sup>*</sup> to align with those in the reference prompt. These regularization terms make the text embedding of S<sup>*</sup> more compatible with existing tokens.
        </p>
        </p>
      </div>
    </div>
  </div>
</div>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Comparisons to Baselines</h2>
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
       <!-- <div class="item"> -->
        <!-- <div class="item"> -->
        <!-- Your image here -->
        <img src="static/images/qualitative_comparsion.png"/>
        <!-- </div> -->
        <!-- <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/additional_qualitative_comparsion.png"/> -->
    </div>
  </div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Face Results</h2>
        <img src="static/images/face.png"/>
    </div>
  </div>
</section>
<!-- End image carousel -->
 
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">More Results</h2>
        <!-- </div> -->
        <!-- <div class="item"> -->
        <!-- Your image here -->
        <img src="static/images/appendix_display.png"/>
        <!-- </div> -->
        <!-- Your image here -->
        <img src="static/images/appendix_display_2.png"/>
    </div>
  </div>
</section>
<!-- End image carousel -->












<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{wu2024core,
          title={CoRe: Context-Regularized Text Embedding Learning for Text-to-Image Personalization},
          author={Wu, Feize and Pang, Yun and Zhang, Junyi and Pang, Lianyu and Yin, Jian and Zhao, Baoquan and Li, Qing and Mao, Xudong},
          journal={arXiv preprint arXiv:2408.15914},
          year={2024}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
